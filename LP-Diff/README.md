<p align="center">
  <a href="https://raw.githubusercontent.com/haoyGONG/LP-Diff/main/figs/results_with_word.png">
    <img src="https://raw.githubusercontent.com/haoyGONG/LP-Diff/main/figs/results_with_word.png" width="80%">
  </a>
</p>

<h1 align="center">LP-Diff: Towards Improved Restoration of Real-World Degraded License Plate</h1>

<p align="center">
  <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Gong_LP-Diff_Towards_Improved_Restoration_of_Real-World_Degraded_License_Plate_CVPR_2025_paper.html"><img src="https://img.shields.io/badge/Paper-CVPR%202025-blue.svg"></a>
</p>

<p align="center">
  <b>Haoyan Gong</b><sup>1</sup>, <b>Zhenrong Zhang</b><sup>1</sup>, <b>Yuzheng Feng</b><sup>1</sup>, <b>Anh Nguyen</b><sup>2</sup>, <b>Hongbin Liu*</b><sup>1</sup><br>
  <sup>1</sup>Xiâ€™an Jiaotong-Liverpool University, <sup>2</sup>University of Liverpool <br>
  <a href="mailto:m.g.haoyan@gmail.com">Contact: m.g.haoyan@gmail.com</a>
</p>

---

## ğŸ“ Abstract

License plate (LP) recognition is crucial for intelligent traffic management. Real-world LP images are often severely degraded due to distance and camera quality, making restoration extremely challenging.  
We introduce the first real-world multi-frame paired LP restoration dataset (**MDLP**, 11,006 groups) and a diffusion-based restoration model LP-Diff featuring: Inter-frame Cross Attention for multi-frame fusion; Texture Enhancement for recovering fine details; Dual-Pathway Fusion for effective channel/spatial selection
Our method **outperforms prior SOTA** on real LP images, both quantitatively and visually.

---

## ğŸ”¥ Highlights

- **[MDLP Dataset]**: First real-world, paired, multi-frame LP restoration dataset (11,006 groups).
    
- **[Diffusion-based Model]**: Custom architecture tailored for license plate restoration.
    
- **[SOTA Performance]**: Best on MDLP for both image quality and LP recognition.
    

---

## ğŸŒŸ Visual Results

**Qualitative comparison on real-world LP images:**

<img src="https://raw.githubusercontent.com/haoyGONG/LP-Diff/main/figs/results_v2.png" width="100%"/>

**These are some confusing letters and complex Chinese characters:**

<img src="https://raw.githubusercontent.com/haoyGONG/LP-Diff/main/figs/char_chinese.png" width="100%"/>


## ğŸ“Š Quantitative Results

|   Method    |  PSNR â†‘   |  SSIM â†‘   |  FID â†“   |  LPIPS â†“  |   NED â†“   |   ACC â†‘   |
| :---------: | :-------: | :-------: | :------: | :-------: | :-------: | :-------: |
|    SRCNN    |   14.01   |   0.195   |  248.3   |   0.517   |   0.626   |   0.041   |
|     HAT     |   14.16   |   0.250   |  229.6   |   0.413   |   0.613   |   0.050   |
| Real-ESRGAN |   13.93   |   0.369   |   31.0   |   0.176   |   0.279   |   0.161   |
|   ResDiff   |   12.00   |   0.269   |   35.9   |   0.277   |   0.292   |   0.159   |
|  ResShift   |   12.53   |   0.321   |   89.1   |   0.288   |   0.332   |   0.099   |
| **LP-Diff** | **14.40** | **0.393** | **22.0** | **0.159** | **0.198** | **0.305** |

_(On MDLP real-world test set. NED: normalized edit distance; ACC: text recognition accuracy)_

---

## ğŸ—ï¸ Model Overview

- **ICAM**: Inter-frame Cross Attention Module
    
- **TEM**: Texture Enhancement Module
    
- **DFM**: Dual-Pathway Fusion Module
    
- **RCDM**: Residual Condition Diffusion Module

 <img src="https://raw.githubusercontent.com/haoyGONG/LP-Diff/main/figs/backbone_v2.png" width="100%"/>

---

## ğŸ“š Dataset

The **MDLP Dataset** consists of 11,006 groups of real-world degraded license plate images. The dataset was collected under diverse real-world conditions, including various distances, illumination changes, and weather conditions. It provides multi-frame degraded images with corresponding clear ground-truth images for robust restoration model training.

**Dataset collection pipeline:**

<img src="https://raw.githubusercontent.com/haoyGONG/LP-Diff/main/figs/data collection.png" width="100%"/>

**Example images:**

<img src="https://raw.githubusercontent.com/haoyGONG/LP-Diff/main/figs/dataset.png" width="100%"/>

**Detail of one license plate image:**

<img src="https://raw.githubusercontent.com/haoyGONG/LP-Diff/main/figs/dataset_onedetail.png" width="100%"/>


---

## ğŸš€ Getting Started

### 1. Installation

- Install Python and required dependencies.
    
- Then install remaining Python packages:
    
    ```bash
    pip install -r requirements.txt
    ```
    

### 2. Download MDLP Dataset

- [Google Drive](https://drive.google.com/file/d/1UpECGcWcF92z-P6pJ9couzGTXb1TMHqk/view?usp=sharing)
    
- [Baidu Netdisk (access code: 1ebm)](https://pan.baidu.com/s/1Aphb_jIx_0tRR71BBbwVwA?pwd=1ebm)
    

### 3. Training & Evaluation

- **Training:**
    
    ```bash
    python run.py -p train -c ./config/LP-Diff.json
    ```
    
- **Validation:**
    
    ```bash
    python run.py -p val -c ./config/LP-Diff.json
    ```
    
- Results and checkpoints are saved in `./experiments`.
    

---

## ğŸ“‚ Project Structure

```
LP-Diff/
â”‚
â”œâ”€â”€ config/              # Training and testing config files
â”œâ”€â”€ data/                # Data loading scripts
â”œâ”€â”€ experiments/         # Model checkpoints and logs
â”œâ”€â”€ figs/                # Visualization images for README and paper
â”œâ”€â”€ models/              # Model implementations
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ run.py               # Main training/testing script
```

---

## ğŸ“– Citation

If you use this work or dataset, please cite:

```bibtex
@inproceedings{gong2025lp,
  title={LP-Diff: Towards Improved Restoration of Real-World Degraded License Plate},
  author={Gong, Haoyan and Zhang, Zhenrong and Feng, Yuzheng and Nguyen, Anh and Liu, Hongbin},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={17831--17840},
  year={2025}
}
```

---

## ğŸ¤ Acknowledgements

This project is based on the excellent [ResDiff](https://github.com/LYL1015/ResDiff/tree/master) codebase.  
We gratefully acknowledge all related open-source works.

---

## ğŸ’¬ Contact

For questions, open an issue or email:  
**[m.g.haoyan@gmail.com](mailto:m.g.haoyan@gmail.com)**

---
